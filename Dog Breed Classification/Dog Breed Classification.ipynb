{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95706a33-f665-4087-adb3-cf514aae96b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from functools import partial\n",
    "\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, ReLU, MaxPooling2D, Dropout, Flatten, Dense\n",
    "from tensorflow.keras.applications import Xception\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "AUTO = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ee3c706-d9e0-449b-a860-a07d1e24a9aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Extract zip file downloaded from kaggle\n",
    "# from zipfile import ZipFile\n",
    "# data_path = r'C:\\Users\\haris\\AI\\ML\\Projects\\Dog Breed Classification\\archive.zip'\n",
    "\n",
    "# with ZipFile(data_path, 'r') as zip:\n",
    "# \tzip.extractall()\n",
    "# \tprint('The data set has been extracted.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b1b185fa-ad76-4430-8380-da29c8fd4fdc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Path to the folders containing images and annotations\n",
    "annotations_folder = r'C:\\Users\\haris\\AI\\ML\\Projects\\Data\\Dog Breed Classification\\annotations'\n",
    "images_folder = r'C:\\Users\\haris\\AI\\ML\\Projects\\Data\\Dog Breed Classification\\images'\n",
    "\n",
    "# Initialize lists to store image data and labels\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "# Parse XML annotations and load images\n",
    "for breed_folder in os.listdir(annotations_folder):\n",
    "    breed_path = os.path.join(annotations_folder, breed_folder)\n",
    "    for annotation_file in os.listdir(breed_path):\n",
    "        annotation_path = os.path.join(breed_path, annotation_file)\n",
    "        \n",
    "        tree = ET.parse(annotation_path)\n",
    "        root = tree.getroot()\n",
    "        \n",
    "        breed = root.find('object/name').text\n",
    "        # xmin = int(root.find('object/bndbox/xmin').text)\n",
    "        # ymin = int(root.find('object/bndbox/ymin').text)\n",
    "        # xmax = int(root.find('object/bndbox/xmax').text)\n",
    "        # ymax = int(root.find('object/bndbox/ymax').text)\n",
    "        \n",
    "        img_path = os.path.join(images_folder, breed_folder, annotation_file + '.jpg')\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.resize(image, (224, 224))  # Resize to desired size\n",
    "        image = image/255\n",
    "        \n",
    "        images.append(image)\n",
    "        labels.append(breed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "86f57d94-c64f-431b-99f8-4c258cc6f05e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20580\n"
     ]
    }
   ],
   "source": [
    "no_of_labels = (len(labels))\n",
    "print(no_of_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "759956be-f330-4036-a157-027bc093dba8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20580, 1)\n",
      "[17]\n"
     ]
    }
   ],
   "source": [
    "# Convert labels to numerical format\n",
    "label_encoder = LabelEncoder()\n",
    "labels_encoded = label_encoder.fit_transform(labels)\n",
    "num_classes = len(label_encoder.classes_)\n",
    "labels_encoded=labels_encoded.reshape(no_of_labels, 1)\n",
    "print(labels_encoded.shape)\n",
    "print(labels_encoded[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e6530bf8-ba7b-4f58-884d-7945b0954dd2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20580, 120)\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the labels\n",
    "labels_encoded_onehot = to_categorical(labels_encoded, num_classes)\n",
    "print(labels_encoded_onehot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "28ea8cf9-3aea-483d-ac57-e656ad23e2f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First row of labels_encoded_onehot:\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Shape of labels_encoded_onehot: (20580, 120)\n"
     ]
    }
   ],
   "source": [
    "# Print the first row\n",
    "print(\"First row of labels_encoded_onehot:\")\n",
    "print(labels_encoded_onehot[0])\n",
    "\n",
    "# Print the shape of the array\n",
    "print(\"Shape of labels_encoded_onehot:\", labels_encoded_onehot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6a3d73fd-34da-4ec1-8f32-d1a574d347b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert the images list to a NumPy array\n",
    "images = np.array(images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "20cc1365-e55d-46bb-a980-ead700419501",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "(10, 1)\n",
      "(10, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "print(labels_encoded)\n",
    "print((labels_encoded.shape))\n",
    "print((images.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1c2a0c8e-7a8e-4efc-bc30-17f95012a4af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8b3128a7-ba2a-467d-bb17-f1ffc8f95c36",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]]\n",
      "(7, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "# Split data into training, validation, and testing sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(images, labels_encoded, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Preprocess the labels\n",
    "y_train_onehot = to_categorical(y_train, num_classes)\n",
    "y_val_onehot = to_categorical(y_val, num_classes)\n",
    "y_test_onehot = to_categorical(y_test, num_classes)\n",
    "\n",
    "print((y_train_onehot))\n",
    "print((X_train).shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "28706246-0656-4080-b63b-08acca9fd2bd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1)\n"
     ]
    }
   ],
   "source": [
    "print(y_temp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "72cfb460-5117-4b87-8a40-d5dad6a974a7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 8.08 GiB for an array with shape (14406, 224, 224, 3) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 72\u001b[0m\n\u001b[0;32m     42\u001b[0m xception_model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# # Data augmentation for Simple CNN\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# datagen = tf.keras.preprocessing.image.ImageDataGenerator(\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m#     horizontal_flip=True,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     70\u001b[0m \n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# Train Simple CNN\u001b[39;00m\n\u001b[1;32m---> 72\u001b[0m history_simple_cnn \u001b[38;5;241m=\u001b[39m \u001b[43msimple_cnn_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_onehot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val_onehot\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# Train Xception\u001b[39;00m\n\u001b[0;32m     75\u001b[0m history_xception \u001b[38;5;241m=\u001b[39m xception_model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train_onehot, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, validation_data\u001b[38;5;241m=\u001b[39m(X_val, y_val_onehot))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    100\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[0;32m    101\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m--> 102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 8.08 GiB for an array with shape (14406, 224, 224, 3) and data type float32"
     ]
    }
   ],
   "source": [
    "# Build Simple CNN\n",
    "def build_simple_cnn(input_shape, num_classes):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Convolutional blocks\n",
    "    for _ in range(4):\n",
    "        model.add(Conv2D(64, (3, 3), padding='same', input_shape=input_shape))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(ReLU())\n",
    "        model.add(MaxPooling2D((2, 2)))\n",
    "        model.add(Dropout(0.25))\n",
    "    \n",
    "    # Flatten and fully connected layers\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Build Xception model with transfer learning\n",
    "def build_xception(input_shape, num_classes):\n",
    "    base_model = Xception(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    model = Sequential()\n",
    "    model.add(base_model)\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "# Specify input shape and number of classes\n",
    "input_shape = (224, 224, 3)  # Example input shape\n",
    "num_classes = 120  # Number of dog breeds\n",
    "\n",
    "# Build and compile Simple CNN model\n",
    "simple_cnn_model = build_simple_cnn(input_shape, num_classes)\n",
    "simple_cnn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Build and compile Xception model\n",
    "xception_model = build_xception(input_shape, num_classes)\n",
    "xception_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # Data augmentation for Simple CNN\n",
    "# datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "#     horizontal_flip=True,\n",
    "#     rotation_range=20,\n",
    "#     width_shift_range=0.2,\n",
    "#     height_shift_range=0.2,\n",
    "#     shear_range=0.2,\n",
    "#     zoom_range=0.2,\n",
    "#     fill_mode='nearest',\n",
    "#     preprocessing_function=tf.keras.applications.xception.preprocess_input\n",
    "# )\n",
    "\n",
    "# # Create data generators using tf.data\n",
    "# def create_data_generator(images, labels, batch_size, is_training=True):\n",
    "#     dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n",
    "#     if is_training:\n",
    "#         dataset = dataset.shuffle(buffer_size=len(images)).repeat()\n",
    "\n",
    "#     dataset = dataset.map(lambda x, y: (datagen.random_transform(x), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "#     dataset = dataset.batch(batch_size).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "#     return dataset\n",
    "\n",
    "# # Create data generators\n",
    "# train_data_generator = create_data_generator(X_train, y_train_onehot, batch_size=32)\n",
    "# val_data_generator = create_data_generator(X_val, y_val_onehot, batch_size=32, is_training=False)\n",
    "# test_data_generator = create_data_generator(X_test, y_test_onehot, batch_size=32, is_training=False)\n",
    "\n",
    "# Train Simple CNN\n",
    "history_simple_cnn = simple_cnn_model.fit(X_train, y_train_onehot, epochs=10, validation_data=(X_val, y_val_onehot))\n",
    "\n",
    "# Train Xception\n",
    "history_xception = xception_model.fit(X_train, y_train_onehot, epochs=10, validation_data=(X_val, y_val_onehot))\n",
    "\n",
    "# Evaluate models\n",
    "simple_cnn_loss, simple_cnn_acc = simple_cnn_model.evaluate(X_test, y_test_onehot, verbose=2)\n",
    "xception_loss, xception_acc = xception_model.evaluate(X_test, y_test_onehot, verbose=2)\n",
    "\n",
    "print(\"Simple CNN - Test accuracy:\", simple_cnn_acc)\n",
    "print(\"Xception - Test accuracy:\", xception_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b4e0b6-b978-4608-80ae-87f15235958e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (tensorflow-gpu)",
   "language": "python",
   "name": "tensorflow-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
