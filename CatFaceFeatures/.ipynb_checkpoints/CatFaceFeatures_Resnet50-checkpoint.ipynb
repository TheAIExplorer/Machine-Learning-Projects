{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffd85dc0-e563-489b-a1c5-a88a27d3d82e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Flatten, Dense, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.utils import Sequence\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e44d2f4e-1589-42e8-a05d-e50f78dcfd56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Avoid OOM errors by setting GPU Memory Consumption Growth\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "# Function to read annotation data from the .cat files\n",
    "def read_annotation_file(annotation_file_path):\n",
    "    with open(annotation_file_path, 'r') as file:\n",
    "        line = file.readline().strip()\n",
    "        values = line.split()\n",
    "        num_points = int(values[0])\n",
    "        annotation_data = [int(value) for value in values[1:]]\n",
    "        return num_points, annotation_data\n",
    "\n",
    "# Path to the directory containing the images and .cat files\n",
    "folder_path = r'C:\\Users\\haris\\AI\\ML\\Projects\\Data\\CatFaceFeatures\\Cats - Original'\n",
    "\n",
    "# Lists to store paths of .jpg files and .cat files\n",
    "image_files_path = []\n",
    "annotation_files_path = []\n",
    "\n",
    "for root, dirs, files in os.walk(folder_path):\n",
    "    for file in files:\n",
    "        if file.lower().endswith(('.jpg', '.jpeg', 'png')):\n",
    "            image_path = os.path.join(root, file)\n",
    "            image_files_path.append(image_path)\n",
    "\n",
    "        if file.lower().endswith('.cat'):\n",
    "            annotation_path = os.path.join(root, file)\n",
    "            annotation_files_path.append(annotation_path)\n",
    "\n",
    "# Lists to store resized image data and annotation data\n",
    "resized_images = []\n",
    "resized_annotations = []\n",
    "\n",
    "image_size = (224, 224)\n",
    "\n",
    "# Read annotation data for each image and apply normalization\n",
    "for annotation_file_path in annotation_files_path:\n",
    "    num_points, annotation_data = read_annotation_file(annotation_file_path)\n",
    "\n",
    "    image = cv2.imread(annotation_file_path[:-4], cv2.IMREAD_COLOR)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    resized_image = cv2.resize(image, image_size)\n",
    "\n",
    "    # Calculate the scaling factor for annotation coordinates\n",
    "    scale_y = resized_image.shape[0] / image.shape[0]\n",
    "    scale_x = resized_image.shape[1] / image.shape[1]\n",
    "\n",
    "    # Apply scaling to the annotation data for both x and y coordinates together\n",
    "    resized_annotation_data = [int(value * scale_x) if i % 2 == 0 else int(value * scale_y) for i, value in enumerate(annotation_data)]\n",
    "\n",
    "    resized_images.append(resized_image)\n",
    "    resized_annotations.append(resized_annotation_data)\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "resized_images = np.array(resized_images)\n",
    "resized_annotations = np.array(resized_annotations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d1f64a7-c02d-4878-ac58-be5fb0ed994d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(resized_images, resized_annotations, test_size=0.1, random_state=42)\n",
    "\n",
    "# Function to load and preprocess the images and annotations in batches\n",
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, x_set, y_set, batch_size):\n",
    "        self.x, self.y = x_set, y_set\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        return np.array(batch_x), np.array(batch_y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631ba2bb-b60d-4d85-bdc0-ec5357d621d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1125/1125 [==============================] - 134s 97ms/step - loss: 9854.3652 - mae: 91.0804 - val_loss: 9004.1250 - val_mae: 87.9667\n",
      "Epoch 2/15\n",
      "1125/1125 [==============================] - 109s 97ms/step - loss: 8102.5532 - mae: 82.9217 - val_loss: 6772.6309 - val_mae: 76.0980\n",
      "Epoch 3/15\n",
      "1125/1125 [==============================] - 109s 97ms/step - loss: 5313.4297 - mae: 65.5923 - val_loss: 4070.9695 - val_mae: 56.9433\n",
      "Epoch 4/15\n",
      "1125/1125 [==============================] - 110s 97ms/step - loss: 2720.4407 - mae: 44.1378 - val_loss: 1958.3684 - val_mae: 36.4638\n",
      "Epoch 5/15\n",
      "1125/1125 [==============================] - 110s 97ms/step - loss: 1105.8407 - mae: 25.6090 - val_loss: 596.0439 - val_mae: 17.5658\n",
      "Epoch 6/15\n",
      "   4/1125 [..............................] - ETA: 1:43 - loss: 762.7664 - mae: 20.3850"
     ]
    }
   ],
   "source": [
    "# Define the model with regularization\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)\n",
    "x = BatchNormalization()(x)\n",
    "predictions = Dense(18, activation='linear')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Unfreeze layers starting from a certain index (e.g., unfreeze layers from 100 onwards)\n",
    "for layer in model.layers[170:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Compile the model\n",
    "initial_learning_rate = 0.0001\n",
    "optimizer = Adam(learning_rate=initial_learning_rate)\n",
    "model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "# Early Stopping Callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "# Train the model with data generator\n",
    "batch_size = 8\n",
    "train_gen = DataGenerator(x_train, y_train, batch_size)\n",
    "test_gen = DataGenerator(x_test, y_test, batch_size)\n",
    "\n",
    "# Train the model with data generator\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    epochs=15,\n",
    "    validation_data=test_gen,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# # Function to plot the training history\n",
    "# def plot_training_history(history):\n",
    "#     plt.figure(figsize=(10, 5))\n",
    "#     plt.subplot(1, 2, 1)\n",
    "#     plt.plot(history.history['loss'], label='Training Loss')\n",
    "#     plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "#     plt.xlabel('Epoch')\n",
    "#     plt.ylabel('Loss')\n",
    "#     plt.legend()\n",
    "\n",
    "#     plt.subplot(1, 2, 2)\n",
    "#     plt.plot(history.history['mae'], label='Training MAE')\n",
    "#     plt.plot(history.history['val_mae'], label='Validation MAE')\n",
    "#     plt.xlabel('Epoch')\n",
    "#     plt.ylabel('Mean Absolute Error (MAE)')\n",
    "#     plt.legend()\n",
    "\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "# # Plot the training history\n",
    "# plot_training_history(history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ad2683-7a2f-4f7d-a6c5-1024eb6bf752",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0779c61-8ca8-4b88-82f7-548acfc848e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0dd1c5-5eb1-46f4-8bc5-a1b0f920e6be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1ca30c-de99-4784-83f1-398c0107026f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c87ea26-89be-4905-ab4d-c47af347f6e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb623c1f-69be-4996-bd03-c1f58655569a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (tensorflow-gpu)",
   "language": "python",
   "name": "tensorflow-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
